{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "import time\n",
    "\n",
    "from config import db_password \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and import our 2 files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"Resources\"\n",
    "# Observation data\n",
    "weather_file = f'../{file_dir}/rcc_data.json'\n",
    "\n",
    "#Parameter File\n",
    "params_file = f'../{file_dir}/params_list.json'\n",
    "\n",
    "# #County File - this is a file downloaded from this government site - https://www2.census.gov/geo/docs/reference/codes/files/st27_mn_cou.txt\n",
    "# county_file = f'../{file_dir}/mn_county_ref.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the read the Observation data JSON file.\n",
    "with open(f'{weather_file}', mode='r') as file:\n",
    "    weather_raw = json.load(file)  # Load the file into a list of Dictionaries NOT RIGHT TO JSON\n",
    "\n",
    "# open the API params file\n",
    "with open(f'{params_file}', mode='r') as file:\n",
    "    params_data = json.load(file)  # Load the file into a list of Dictionaries NOT RIGHT TO JSON\n",
    "\n",
    "# # open the MN county reference\n",
    "# county_df = pd.read_csv(county_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MN</th>\n",
       "      <th>27</th>\n",
       "      <th>001</th>\n",
       "      <th>Aitkin County</th>\n",
       "      <th>H1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>Anoka County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>Becker County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>Beltrami County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>Benton County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>Big Stone County</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MN  27  001     Aitkin County  H1\n",
       "0  MN  27    3      Anoka County  H1\n",
       "1  MN  27    5     Becker County  H1\n",
       "2  MN  27    7   Beltrami County  H1\n",
       "3  MN  27    9     Benton County  H1\n",
       "4  MN  27   11  Big Stone County  H1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# county_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(weather_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the API parameters we used into a dataframe\n",
    "# We need the parameters to know the date range and the values in the observation Array\n",
    "params_df = pd.DataFrame(params_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out the JSON data into a Stations Dataframe and an Observations Dataframe\n",
    "counter = 0\n",
    "stations_list =[]\n",
    "observations_list = []\n",
    "\n",
    "# Convert the start/end date used in the API call stored in the params file\n",
    "startDate = pd.to_datetime(params_df['sdate'][0])\n",
    "endDate = pd.to_datetime(params_df['edate'][0])\n",
    "\n",
    "# Loop through the upper most level of the JSON file called \"data\"\n",
    "for observation in weather_raw['data']:\n",
    "\n",
    "    # Create a list of stations\n",
    "    stations_list.append(observation[\"meta\"])\n",
    "        \n",
    "    # Start the current date at the first date in the range for each stations observations\n",
    "    currentDate = startDate\n",
    "    \n",
    "    # Loop through the stations observations and create a list of observations\n",
    "    for observation_data in observation[\"data\"]:\n",
    "        observations_list.append({\"station_uid\":observation[\"meta\"]['uid'],\"date\":currentDate, \"data\":observation_data})\n",
    "\n",
    "        # Increment the date by one day\n",
    "        currentDate = currentDate + timedelta(days=1)\n",
    "\n",
    "        # Increment our counter (for debugging use)\n",
    "        counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert our lists to dataframes\n",
    "stations_df = pd.DataFrame(stations_list)\n",
    "observations_df = pd.DataFrame(observations_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130912</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>[M, M, 1.52, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130913</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>[M, M, 0.02, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130914</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>[M, M, 0.00, 0.0, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130915</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>[M, M, 0.00, 0.0, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130916</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>[M, M, 0.00, 0.0, M, M]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_uid       date                     data\n",
       "130912        96447 2022-05-12    [M, M, 1.52, M, M, M]\n",
       "130913        96447 2022-05-13    [M, M, 0.02, M, M, M]\n",
       "130914        96447 2022-05-14  [M, M, 0.00, 0.0, M, M]\n",
       "130915        96447 2022-05-15  [M, M, 0.00, 0.0, M, M]\n",
       "130916        96447 2022-05-16  [M, M, 0.00, 0.0, M, M]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the ll list into Latitude and longitude \n",
    "split_df = pd.DataFrame(stations_df['ll'].to_list(), columns = ['latitude','longitude'])\n",
    "# concat df and split_df\n",
    "stations_df = pd.concat([stations_df, split_df], axis=1)\n",
    "# Drop ll column.\n",
    "stations_df = stations_df.drop(columns=[\"ll\"])\n",
    "# # display df\n",
    "# stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create sids columns for the array sids\n",
    "# sids = []\n",
    "# sid_string = \"\"\n",
    "# counter = 1\n",
    "# for x in range(stations_df.sids.map(len).max()):\n",
    "#   sids.append(f\"sid_{counter}\")\n",
    "#   sid_string = f\"{sid_string}, 'sid_{counter}'\"\n",
    "#   counter = counter + 1\n",
    "\n",
    "# # split the array into separate columns\n",
    "# split_df = pd.DataFrame(stations_df['sids'].to_list(), columns = sids)\n",
    "\n",
    "# # concat df and split_df\n",
    "# stations_df = pd.concat([stations_df, split_df], axis=1)\n",
    "\n",
    "# # Drop names from columns.\n",
    "stations_df = stations_df.drop(columns=[\"sids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns in the DF - Remove the valid_daterange and sid_dates since they are not necessary\n",
    "#column_list = f\"['uid','name','county','state','latitude','longitude','climdiv'{sid_string}]\"  #'valid_daterange','sid_dates'\n",
    "column_list = f\"['uid','name','county','state','latitude','longitude','climdiv']\"  #'valid_daterange','sid_dates'\n",
    "\n",
    "# change the string into an array for the reordering\n",
    "columnArray = literal_eval(column_list)\n",
    "\n",
    "stations_df= stations_df.loc[:, columnArray]\n",
    "stations_df.rename(columns={'uid':'station_uid'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the observations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130912</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>[M, M, 1.52, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130913</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>[M, M, 0.02, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130914</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>[M, M, 0.00, 0.0, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130915</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>[M, M, 0.00, 0.0, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130916</th>\n",
       "      <td>96447</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>[M, M, 0.00, 0.0, M, M]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_uid       date                     data\n",
       "130912        96447 2022-05-12    [M, M, 1.52, M, M, M]\n",
       "130913        96447 2022-05-13    [M, M, 0.02, M, M, M]\n",
       "130914        96447 2022-05-14  [M, M, 0.00, 0.0, M, M]\n",
       "130915        96447 2022-05-15  [M, M, 0.00, 0.0, M, M]\n",
       "130916        96447 2022-05-16  [M, M, 0.00, 0.0, M, M]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130050</th>\n",
       "      <td>96447</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130051</th>\n",
       "      <td>96447</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130052</th>\n",
       "      <td>96447</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130053</th>\n",
       "      <td>96447</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130054</th>\n",
       "      <td>96447</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_uid       date                data\n",
       "130050        96447 2020-01-01  [M, M, M, M, M, M]\n",
       "130051        96447 2020-01-02  [M, M, M, M, M, M]\n",
       "130052        96447 2020-01-03  [M, M, M, M, M, M]\n",
       "130053        96447 2020-01-04  [M, M, M, M, M, M]\n",
       "130054        96447 2020-01-05  [M, M, M, M, M, M]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = observations_df.loc[(observations_df['station_uid'] == 96447)]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data columns into the elems requested\n",
    "elems = str(params_df[\"elems\"][0])\n",
    "\n",
    "elems = elems.replace(\",\",\"','\")\n",
    "\n",
    "# convert the elems from the params list to a string for splitting apart the Array \n",
    "column_list = f\"['{elems}']\"\n",
    "columnArray = literal_eval(column_list)\n",
    "\n",
    "# split the array into separate columns]\n",
    "split_df = pd.DataFrame(observations_df['data'].to_list(), columns = columnArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any of the \"M\" values with NaN in the data.  This is a Missing Value\n",
    "split_df.replace(\"M\",np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any of the \"T\" values with 0 in the data.  This is a trace amount of precipitation\n",
    "split_df.replace(\"T\",0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up the data returned based on the Elements stored in the params json file\n",
    "\n",
    "# concat df and split_df\n",
    "observations_df = pd.concat([observations_df, split_df], axis=1)\n",
    "# Drop data column.\n",
    "observations_df = observations_df.drop(columns=[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    130917\n",
       "date           130917\n",
       "maxt             6412\n",
       "mint             6412\n",
       "pcpn            66699\n",
       "snow            39934\n",
       "snwd             9522\n",
       "avgt             6406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any observations where it's missing a min temperature\n",
    "observations_df = observations_df.dropna(subset=['mint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    6412\n",
       "date           6412\n",
       "maxt           6406\n",
       "mint           6412\n",
       "pcpn           6213\n",
       "snow           4157\n",
       "snwd           3229\n",
       "avgt           6406\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the datatypes of the columns to numeric\n",
    "observations_df[columnArray] = observations_df[columnArray].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    151\n",
       "name           151\n",
       "county         151\n",
       "state          151\n",
       "latitude       151\n",
       "longitude      151\n",
       "climdiv        151\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = stations_df[stations_df.station_uid.isin(observations_df['station_uid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    8\n",
       "name           8\n",
       "county         8\n",
       "state          8\n",
       "latitude       8\n",
       "longitude      8\n",
       "climdiv        8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid      int64\n",
       "name            object\n",
       "county          object\n",
       "state           object\n",
       "latitude       float64\n",
       "longitude      float64\n",
       "climdiv         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create calculated fields for dashboard and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a freeze_day column based on min temperature\n",
    "observations_df['freeze_day'] = np.where(observations_df['mint'] <= 32, 1, 0)\n",
    "\n",
    "# Flag if it reaches above freezing on the day\n",
    "observations_df['above_freezing'] = np.where(observations_df['maxt'] > 32, 1, 0)\n",
    "\n",
    "# Create columns for the different date parts to make processing easier\n",
    "observations_df['obs_year'] = pd.to_datetime(observations_df['date']).dt.year\n",
    "observations_df['obs_month'] = pd.to_datetime(observations_df['date']).dt.month\n",
    "observations_df['obs_day'] = pd.to_datetime(observations_df['date']).dt.day\n",
    "observations_df['obs_dayofyear'] = pd.to_datetime(observations_df['date']).dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Station/Year dataframe creation and calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>climdiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10392</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.17559</td>\n",
       "      <td>44.66600</td>\n",
       "      <td>MN09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10395</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.09798</td>\n",
       "      <td>44.71673</td>\n",
       "      <td>MN09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10398</td>\n",
       "      <td>HASTINGS DAM 2</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-92.86890</td>\n",
       "      <td>44.75970</td>\n",
       "      <td>MN09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10685</td>\n",
       "      <td>LOWER ST. ANTHONY FALLS</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.24690</td>\n",
       "      <td>44.97840</td>\n",
       "      <td>MN06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10408</td>\n",
       "      <td>MINNEAPOLIS FLYING CLOUD AIRPORT</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.47051</td>\n",
       "      <td>44.83214</td>\n",
       "      <td>MN06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10410</td>\n",
       "      <td>MINNEAPOLIS-ST. PAUL INTERNATIONAL AIRPORT</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.23133</td>\n",
       "      <td>44.88523</td>\n",
       "      <td>MN06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10430</td>\n",
       "      <td>NEW HOPE</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.37920</td>\n",
       "      <td>45.01000</td>\n",
       "      <td>MN06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10442</td>\n",
       "      <td>MINNEAPOLIS CRYSTAL AIRPORT</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.35107</td>\n",
       "      <td>45.06222</td>\n",
       "      <td>MN06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid                                        name county state  \\\n",
       "0        10392                              FARMINGTON 3NW  27037    MN   \n",
       "1        10395      ROSEMOUNT RESEARCH AND OUTREACH CENTER  27037    MN   \n",
       "2        10398                              HASTINGS DAM 2  27037    MN   \n",
       "3        10685                     LOWER ST. ANTHONY FALLS  27053    MN   \n",
       "4        10408            MINNEAPOLIS FLYING CLOUD AIRPORT  27053    MN   \n",
       "5        10410  MINNEAPOLIS-ST. PAUL INTERNATIONAL AIRPORT  27053    MN   \n",
       "6        10430                                    NEW HOPE  27053    MN   \n",
       "9        10442                 MINNEAPOLIS CRYSTAL AIRPORT  27053    MN   \n",
       "\n",
       "   latitude  longitude climdiv  \n",
       "0 -93.17559   44.66600    MN09  \n",
       "1 -93.09798   44.71673    MN09  \n",
       "2 -92.86890   44.75970    MN09  \n",
       "3 -93.24690   44.97840    MN06  \n",
       "4 -93.47051   44.83214    MN06  \n",
       "5 -93.23133   44.88523    MN06  \n",
       "6 -93.37920   45.01000    MN06  \n",
       "9 -93.35107   45.06222    MN06  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to store yearly summary info by station ID\n",
    "years = pd.to_datetime(observations_df['date']).dt.year.unique()\n",
    "years_df = pd.DataFrame(years,columns=['obs_year'])\n",
    "station_yearly_metrics_df = pd.merge(stations_df['station_uid'], years_df, how='cross')\n",
    "station_yearly_metrics_df = station_yearly_metrics_df.set_index(['station_uid','obs_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last frost date of each station for each year of data\n",
    "last_freeze_df = observations_df.loc[(observations_df['freeze_day']==1)  & (observations_df['obs_dayofyear'] < 180),['station_uid','date','obs_year','obs_dayofyear'] ]. \\\n",
    "        groupby([\"station_uid\",\"obs_year\"])[['date','obs_dayofyear']].max().rename(columns={'date':'last_freeze_date','obs_dayofyear':'last_freeze_dayofyear'})\n",
    "\n",
    "# get the first freeze in the fall\n",
    "first_freeze_df = observations_df.loc[(observations_df['freeze_day']==1)  & (observations_df['obs_dayofyear'] >= 180),['station_uid','date','obs_year','obs_dayofyear'] ]. \\\n",
    "        groupby([\"station_uid\",\"obs_year\"])[['date','obs_dayofyear']].min().rename(columns={'date':'first_freeze_date','obs_dayofyear':'first_freeze_dayofyear'})\n",
    "\n",
    "# Determine if we have a complete set of observations for april to may for each station/year\n",
    "april_to_may_days_recorderd_df = pd.DataFrame(observations_df.loc[(observations_df['obs_month']>=4 )&(observations_df['obs_month'] <= 6),['station_uid','obs_year','mint']]\\\n",
    "        .groupby(['station_uid','obs_year'])['mint'].count()).rename(columns={'mint':'observations_recorded_april_to_may'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coldest_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_uid</th>\n",
       "      <th>obs_year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10392</th>\n",
       "      <th>2021</th>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10395</th>\n",
       "      <th>2020</th>\n",
       "      <td>-18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      coldest_day\n",
       "station_uid obs_year             \n",
       "10392       2021             -8.0\n",
       "            2022            -20.0\n",
       "10395       2020            -18.0\n",
       "            2021            -23.0\n",
       "            2022            -22.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get the coldest day of the year\n",
    "coldest_day_of_year = observations_df.groupby([\"station_uid\",\"obs_year\"])[['mint']].min().rename(columns={'mint':'coldest_day'})\n",
    "coldest_day_of_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>obs_year</th>\n",
       "      <th>coldest_day</th>\n",
       "      <th>coldest_dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10392</td>\n",
       "      <td>2021</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10392</td>\n",
       "      <td>2022</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10395</td>\n",
       "      <td>2020</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10395</td>\n",
       "      <td>2021</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10395</td>\n",
       "      <td>2022</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid  obs_year  coldest_day  coldest_dayofyear\n",
       "0        10392      2021         -8.0                363\n",
       "1        10392      2022        -20.0                 26\n",
       "2        10395      2020        -18.0                 45\n",
       "3        10395      2021        -23.0                 38\n",
       "4        10395      2022        -22.0                 26"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldest_day_df = pd.merge(coldest_day_of_year, observations_df, how='left', left_on=['station_uid', 'obs_year','coldest_day'], right_on = [\"station_uid\",\"obs_year\",\"mint\"])\n",
    "coldest_day_of_year_df = pd.DataFrame(coldest_day_df.groupby([\"station_uid\",\"obs_year\",'coldest_day'])['obs_dayofyear'].max())\n",
    "coldest_day_of_year_df.rename(columns={'obs_dayofyear':'coldest_dayofyear'},inplace=True)\n",
    "coldest_day_of_year_df = coldest_day_of_year_df.reset_index()\n",
    "coldest_day_of_year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldest_day_of_year_df = coldest_day_of_year_df.set_index(keys=['station_uid','obs_year'])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, coldest_day_of_year_df, how='left', left_index=True, right_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station_yearly_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = station_yearly_metrics_df.loc[(station_yearly_metrics_df['station_uid'] == 40882)]\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hottest day of the year, if there are multiple days with the temperature, use the latest one in the year (the one closest to the next last freeze date the next spring)\n",
    "hottest_day_of_year = observations_df.groupby([\"station_uid\",\"obs_year\"])[['maxt']].max().rename(columns={'maxt':'hottest_day'})\n",
    "hottest_day_df = pd.merge(hottest_day_of_year, observations_df, how='left', left_on=['station_uid', 'obs_year','hottest_day'], right_on = [\"station_uid\",\"obs_year\",\"maxt\"])\n",
    "hottest_day_of_year_df = pd.DataFrame(hottest_day_df.groupby([\"station_uid\",\"obs_year\",'hottest_day'])['obs_dayofyear'].max())\n",
    "hottest_day_of_year_df.rename(columns={'obs_dayofyear':'hottest_dayofyear'},inplace=True)\n",
    "hottest_day_of_year_df = hottest_day_of_year_df.reset_index()\n",
    "hottest_day_of_year_df = hottest_day_of_year_df.set_index(keys=['station_uid','obs_year'])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, hottest_day_of_year_df, how='left', left_index=True, right_index =True)\n",
    "#hottest_day_of_year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station_yearly_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the yearly data \n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, last_freeze_df, how='left', left_on=['station_uid','obs_year'], right_index=True) #,  left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, first_freeze_df, how='left', left_on=['station_uid','obs_year'], right_index=True) # ,  left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, april_to_may_days_recorderd_df, how='left', left_on=['station_uid','obs_year'], right_index=True) # ,  left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station_yearly_metrics_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of calculations for the Stations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean/average last freeze date for a station \n",
    "avg_last_freeze_df = pd.DataFrame(station_yearly_metrics_df.groupby(['station_uid'])['last_freeze_dayofyear'].mean().round(0)).rename(columns={'last_freeze_dayofyear':'avg_last_freeze_dayofyear'})\n",
    "\n",
    "# Convert the day of year to a string value for mm/dd\n",
    "avg_last_freeze_df[\"avg_last_freeze_mm_dd\"] = pd.to_datetime(avg_last_freeze_df[\"avg_last_freeze_dayofyear\"],format='%j').dt.strftime('%m/%d')\n",
    "\n",
    "# determine the mean, get the string value\n",
    "median_last_freeze_df = pd.DataFrame(station_yearly_metrics_df.groupby(['station_uid'])['last_freeze_dayofyear'].median().round(0)).rename(columns={'last_freeze_dayofyear':'median_last_freeze_dayofyear'})\n",
    "median_last_freeze_df[\"median_last_freeze_mm_dd\"] = pd.to_datetime(median_last_freeze_df[\"median_last_freeze_dayofyear\"],format='%j').dt.strftime('%m/%d')\n",
    "\n",
    "# Merge the values into a single table\n",
    "station_metrics_df = pd.merge(stations_df, avg_last_freeze_df, left_on=['station_uid'], right_on = ['station_uid'])\n",
    "station_metrics_df = pd.merge(station_metrics_df, median_last_freeze_df, left_on=['station_uid'], right_on = ['station_uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_yearly_metrics_df.reset_index(inplace=True)\n",
    "# station_yearly_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the station metrics and station/yearly DF to determine metrics for each station\n",
    "merged_station_and_yearly_df = pd.merge(station_yearly_metrics_df, station_metrics_df, how=\"left\", on=[\"station_uid\", \"station_uid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a count of how many years the station is in the dataset\n",
    "stations_years_count = merged_station_and_yearly_df.groupby(\"station_uid\").count()[\"obs_year\"]\n",
    "\n",
    "# Calculate the number of years where the last freeze was before or on the average date\n",
    "stations_count_at_or_before_avg_last_freeze = merged_station_and_yearly_df[(merged_station_and_yearly_df[\"last_freeze_dayofyear\"] <= merged_station_and_yearly_df['avg_last_freeze_dayofyear'])]\n",
    "stations_count_at_or_before_avg_last_freeze = stations_count_at_or_before_avg_last_freeze.groupby(\"station_uid\").count()[\"obs_year\"]\n",
    "\n",
    "# Calculate the number of years where the last freeze was after the average date\n",
    "stations_count_later_than_avg_last_freeze = merged_station_and_yearly_df[(merged_station_and_yearly_df[\"last_freeze_dayofyear\"] > merged_station_and_yearly_df['avg_last_freeze_dayofyear'])]\n",
    "stations_count_later_than_avg_last_freeze = stations_count_later_than_avg_last_freeze.groupby(\"station_uid\").count()[\"obs_year\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_included</th>\n",
       "      <th>count_at_or_before_avg_last_freeze</th>\n",
       "      <th>count_later_than_avg_last_freeze</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10430</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             years_included  count_at_or_before_avg_last_freeze  \\\n",
       "station_uid                                                       \n",
       "10392                     3                                   1   \n",
       "10395                     3                                   1   \n",
       "10398                     3                                   1   \n",
       "10408                     3                                   2   \n",
       "10410                     3                                   2   \n",
       "10430                     3                                   1   \n",
       "10442                     3                                   1   \n",
       "10685                     3                                   2   \n",
       "\n",
       "             count_later_than_avg_last_freeze  \n",
       "station_uid                                    \n",
       "10392                                       1  \n",
       "10395                                       2  \n",
       "10398                                       2  \n",
       "10408                                       1  \n",
       "10410                                       1  \n",
       "10430                                       2  \n",
       "10442                                       2  \n",
       "10685                                       1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_calc_values_df = pd.DataFrame(\n",
    "          {\"years_included\": stations_years_count,\n",
    "          \"count_at_or_before_avg_last_freeze\": stations_count_at_or_before_avg_last_freeze, \n",
    "          \"count_later_than_avg_last_freeze\": stations_count_later_than_avg_last_freeze})\n",
    "# station_calc_values_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>climdiv</th>\n",
       "      <th>avg_last_freeze_dayofyear</th>\n",
       "      <th>avg_last_freeze_mm_dd</th>\n",
       "      <th>median_last_freeze_dayofyear</th>\n",
       "      <th>median_last_freeze_mm_dd</th>\n",
       "      <th>years_included</th>\n",
       "      <th>count_at_or_before_avg_last_freeze</th>\n",
       "      <th>count_later_than_avg_last_freeze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10392</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.17559</td>\n",
       "      <td>44.66600</td>\n",
       "      <td>MN09</td>\n",
       "      <td>124.0</td>\n",
       "      <td>05/04</td>\n",
       "      <td>124.0</td>\n",
       "      <td>05/04</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10395</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.09798</td>\n",
       "      <td>44.71673</td>\n",
       "      <td>MN09</td>\n",
       "      <td>127.0</td>\n",
       "      <td>05/07</td>\n",
       "      <td>131.0</td>\n",
       "      <td>05/11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10398</td>\n",
       "      <td>HASTINGS DAM 2</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-92.86890</td>\n",
       "      <td>44.75970</td>\n",
       "      <td>MN09</td>\n",
       "      <td>106.0</td>\n",
       "      <td>04/16</td>\n",
       "      <td>108.0</td>\n",
       "      <td>04/18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10685</td>\n",
       "      <td>LOWER ST. ANTHONY FALLS</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.24690</td>\n",
       "      <td>44.97840</td>\n",
       "      <td>MN06</td>\n",
       "      <td>114.0</td>\n",
       "      <td>04/24</td>\n",
       "      <td>112.0</td>\n",
       "      <td>04/22</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10408</td>\n",
       "      <td>MINNEAPOLIS FLYING CLOUD AIRPORT</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.47051</td>\n",
       "      <td>44.83214</td>\n",
       "      <td>MN06</td>\n",
       "      <td>115.0</td>\n",
       "      <td>04/25</td>\n",
       "      <td>115.0</td>\n",
       "      <td>04/25</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10410</td>\n",
       "      <td>MINNEAPOLIS-ST. PAUL INTERNATIONAL AIRPORT</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.23133</td>\n",
       "      <td>44.88523</td>\n",
       "      <td>MN06</td>\n",
       "      <td>113.0</td>\n",
       "      <td>04/23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>04/22</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10430</td>\n",
       "      <td>NEW HOPE</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.37920</td>\n",
       "      <td>45.01000</td>\n",
       "      <td>MN06</td>\n",
       "      <td>127.0</td>\n",
       "      <td>05/07</td>\n",
       "      <td>131.0</td>\n",
       "      <td>05/11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10442</td>\n",
       "      <td>MINNEAPOLIS CRYSTAL AIRPORT</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.35107</td>\n",
       "      <td>45.06222</td>\n",
       "      <td>MN06</td>\n",
       "      <td>127.0</td>\n",
       "      <td>05/07</td>\n",
       "      <td>131.0</td>\n",
       "      <td>05/11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid                                        name county state  \\\n",
       "0        10392                              FARMINGTON 3NW  27037    MN   \n",
       "1        10395      ROSEMOUNT RESEARCH AND OUTREACH CENTER  27037    MN   \n",
       "2        10398                              HASTINGS DAM 2  27037    MN   \n",
       "3        10685                     LOWER ST. ANTHONY FALLS  27053    MN   \n",
       "4        10408            MINNEAPOLIS FLYING CLOUD AIRPORT  27053    MN   \n",
       "5        10410  MINNEAPOLIS-ST. PAUL INTERNATIONAL AIRPORT  27053    MN   \n",
       "6        10430                                    NEW HOPE  27053    MN   \n",
       "7        10442                 MINNEAPOLIS CRYSTAL AIRPORT  27053    MN   \n",
       "\n",
       "   latitude  longitude climdiv  avg_last_freeze_dayofyear  \\\n",
       "0 -93.17559   44.66600    MN09                      124.0   \n",
       "1 -93.09798   44.71673    MN09                      127.0   \n",
       "2 -92.86890   44.75970    MN09                      106.0   \n",
       "3 -93.24690   44.97840    MN06                      114.0   \n",
       "4 -93.47051   44.83214    MN06                      115.0   \n",
       "5 -93.23133   44.88523    MN06                      113.0   \n",
       "6 -93.37920   45.01000    MN06                      127.0   \n",
       "7 -93.35107   45.06222    MN06                      127.0   \n",
       "\n",
       "  avg_last_freeze_mm_dd  median_last_freeze_dayofyear  \\\n",
       "0                 05/04                         124.0   \n",
       "1                 05/07                         131.0   \n",
       "2                 04/16                         108.0   \n",
       "3                 04/24                         112.0   \n",
       "4                 04/25                         115.0   \n",
       "5                 04/23                         112.0   \n",
       "6                 05/07                         131.0   \n",
       "7                 05/07                         131.0   \n",
       "\n",
       "  median_last_freeze_mm_dd  years_included  \\\n",
       "0                    05/04               3   \n",
       "1                    05/11               3   \n",
       "2                    04/18               3   \n",
       "3                    04/22               3   \n",
       "4                    04/25               3   \n",
       "5                    04/22               3   \n",
       "6                    05/11               3   \n",
       "7                    05/11               3   \n",
       "\n",
       "   count_at_or_before_avg_last_freeze  count_later_than_avg_last_freeze  \n",
       "0                                   1                                 1  \n",
       "1                                   1                                 2  \n",
       "2                                   1                                 2  \n",
       "3                                   2                                 1  \n",
       "4                                   2                                 1  \n",
       "5                                   2                                 1  \n",
       "6                                   1                                 2  \n",
       "7                                   1                                 2  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_metrics_full_df = pd.merge(station_metrics_df, station_calc_values_df, how=\"left\", on=[\"station_uid\", \"station_uid\"])\n",
    "# station_metrics_full_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Observation Day Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_calcs_loop(date_range):\n",
    "    counter = 0\n",
    "    observation_calcs_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through all the observations and calculate the metrics based on the number of days previous passed in\n",
    "    for index, row in observations_df.iterrows():\n",
    "        # call function to get previous X days of data\n",
    "\n",
    "        df = pd.DataFrame(observations_df.loc[(observations_df.station_uid == row['station_uid']) & \\\n",
    "                            (observations_df.date < row['date']) & \\\n",
    "                            (observations_df.date >= row['date'] - timedelta(days=date_range))] \\\n",
    "                    .groupby('station_uid').agg(max_temp=('maxt', 'max'), \n",
    "                            min_temp=('mint', 'min'),\n",
    "                            avgt=('avgt','mean'),\n",
    "                            precip=('pcpn','sum'),\n",
    "                            count=('date','count')) \\\n",
    "                    .reset_index(drop=True))\n",
    "\n",
    "        df['source_index'] = index\n",
    "\n",
    "        observation_calcs_df = pd.concat([observation_calcs_df,df], ignore_index=True)\n",
    "        \n",
    "    # Rename the columns for the range\n",
    "    column_array = [f'maxt_{date_range}_day', f'mint_{date_range}_day', f'avgt_{date_range}_day', f'precip_{date_range}_day',f'obs_count_{date_range}_day','source_index']\n",
    "    observation_calcs_df.columns = column_array\n",
    "\n",
    "    observation_calcs_df = observation_calcs_df.set_index(\"source_index\")\n",
    "    return observation_calcs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function for 7 days and merge the new columns into the table\n",
    "observations_calcs_7_day = observation_calcs_loop(7)\n",
    "observations_new_df = pd.merge(observations_df, observations_calcs_7_day, how=\"left\", left_index=True, right_index=True)\n",
    "# observations_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function for 30 days and merge the new columns into the table\n",
    "observations_calcs_30_day = observation_calcs_loop(30)\n",
    "observations_new_df = pd.merge(observations_new_df, observations_calcs_30_day, how=\"left\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Output file (CSV\n",
    "output_station_file = \"../Resources/station_data.csv\"\n",
    "output_station_year_file = \"../Resources/station_year_data.csv\"\n",
    "output_observation_file = \"../Resources/observation_data.csv\"\n",
    "\n",
    "station_metrics_full_df.to_csv(output_station_file, index=False)\n",
    "station_yearly_metrics_df.to_csv(output_station_year_file, index=False)\n",
    "observations_new_df.to_csv(output_observation_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL movie_data DB\n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/last_freeze_analysis\"\n",
    "\n",
    "# Create the database engine with the following line \n",
    "engine = create_engine(db_string)\n",
    "\n",
    "# These two drop statements are to cleanup an old set of tablenames\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"DROP TABLE IF EXISTS stations;\")\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"DROP TABLE IF EXISTS observations;\")\n",
    "\n",
    "# Drop the view since we'll recreate it later\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"DROP VIEW IF EXISTS v_days_until_freeze_calcs_0_to_180_days;\")\n",
    "\n",
    "# RECREATE THE TABLES WITH DATA.  CREATE IN THIS ORDER TO DEAL WITH FK's\n",
    "# Save the observations DataFrame to a SQL table \"observations\"- Replace the table if it already exists\n",
    "observations_new_df.to_sql(name='observation', con=engine, if_exists='replace', index=False)   \n",
    "\n",
    "# Save the stations DataFrame to a SQL table \"stations\"- Replace the table if it already exists\n",
    "station_yearly_metrics_df.to_sql(name='station_yearly', con=engine, if_exists='replace', index=False)   \n",
    "\n",
    "# Save the stations DataFrame to a SQL table \"stations\"- Replace the table if it already exists\n",
    "station_metrics_full_df.to_sql(name='station', con=engine, if_exists='replace', index=False)   \n",
    "\n",
    "\n",
    "\n",
    "# Add primary keys\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE station ADD PRIMARY KEY (station_uid);\")\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE station_yearly ADD PRIMARY KEY (station_uid,obs_year);\")\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE observation ADD PRIMARY KEY (station_uid,date);\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view for additional calculations\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"CREATE OR REPLACE VIEW v_days_until_freeze_calcs_0_to_180_days \\\n",
    "                AS SELECT o.station_uid, o.date, s.avg_last_freeze_dayofyear - o.obs_dayofyear AS days_until_avg_freeze_dayofyear, \\\n",
    "                sy.last_freeze_dayofyear - o.obs_dayofyear AS days_until_current_year_last_freeze_dayofyear \\\n",
    "                FROM observation o \\\n",
    "                JOIN station_yearly sy ON sy.station_uid = o.station_uid AND sy.obs_year = o.obs_year \\\n",
    "                JOIN station s ON sy.station_uid = s.station_uid \\\n",
    "                WHERE o.obs_dayofyear >= 0 AND o.obs_dayofyear < 180;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add foreign keys\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE station_yearly ADD CONSTRAINT stn_yrly_station_uid_fk FOREIGN KEY (station_uid) REFERENCES station (station_uid);\")\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE observation ADD CONSTRAINT obs_station_uid_fk FOREIGN KEY (station_uid) REFERENCES station (station_uid);\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of script\n"
     ]
    }
   ],
   "source": [
    "print('end of script')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79cce83be72e55c1187b298660b26fa831a7f54746f9fd5c4205698cac5dca1a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
