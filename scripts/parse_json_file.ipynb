{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "import time\n",
    "\n",
    "from config import db_password "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"Resources\"\n",
    "# Observation data\n",
    "weather_file = f'../{file_dir}/example_data.json'\n",
    "\n",
    "#Parameter File\n",
    "params_file = f'../{file_dir}/params_list.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the read the Observation data JSON file.\n",
    "with open(f'{weather_file}', mode='r') as file:\n",
    "    weather_raw = json.load(file)  # Load the file into a list of Dictionaries NOT RIGHT TO JSON\n",
    "\n",
    "with open(f'{params_file}', mode='r') as file:\n",
    "    params_data = json.load(file)  # Load the file into a list of Dictionaries NOT RIGHT TO JSON\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(weather_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the API parameters we used into a dataframe\n",
    "# We need the parameters to know the date range and the values in the observation Array\n",
    "params_df = pd.DataFrame(params_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out the JSON data into a Stations Dataframe and an Observations Dataframe\n",
    "counter = 0\n",
    "stations_list =[]\n",
    "observations_list = []\n",
    "\n",
    "# Convert the start/end date used in the API call stored in the params file\n",
    "startDate = pd.to_datetime(params_df['sdate'][0])\n",
    "endDate = pd.to_datetime(params_df['edate'][0])\n",
    "\n",
    "# Loop through the upper most level of the JSON file called \"data\"\n",
    "for observation in weather_raw['data']:\n",
    "\n",
    "    # Create a list of stations\n",
    "    stations_list.append(observation[\"meta\"])\n",
    "        \n",
    "    # Start the current date at the first date in the range for each stations observations\n",
    "    currentDate = startDate\n",
    "    \n",
    "    # Loop through the stations observations and create a list of observations\n",
    "    for observation_data in observation[\"data\"]:\n",
    "        observations_list.append({\"station_uid\":observation[\"meta\"]['uid'],\"date\":currentDate, \"data\":observation_data})\n",
    "\n",
    "        # Increment the date by one day\n",
    "        currentDate = currentDate + timedelta(days=1)\n",
    "\n",
    "        # Increment our counter (for debugging use)\n",
    "        counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert our lists to dataframes\n",
    "stations_df = pd.DataFrame(stations_list)\n",
    "observations_df = pd.DataFrame(observations_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-02</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-03</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-04</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-05</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid       date                data\n",
       "0        10373 2002-01-01  [M, M, M, M, M, M]\n",
       "1        10373 2002-01-02  [M, M, M, M, M, M]\n",
       "2        10373 2002-01-03  [M, M, M, M, M, M]\n",
       "3        10373 2002-01-04  [M, M, M, M, M, M]\n",
       "4        10373 2002-01-05  [M, M, M, M, M, M]"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_daterange</th>\n",
       "      <th>name</th>\n",
       "      <th>ll</th>\n",
       "      <th>sids</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>elev</th>\n",
       "      <th>climdiv</th>\n",
       "      <th>uid</th>\n",
       "      <th>sid_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[1893-01-01, 1893-05-31], [1893-01-01, 1893-0...</td>\n",
       "      <td>NORTHFIELD 2NNE</td>\n",
       "      <td>[-93.1486, 44.4753]</td>\n",
       "      <td>[215987 2, USC00215987 6, NFDM5 7, NRFM5 7]</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>890.0</td>\n",
       "      <td>MN08</td>\n",
       "      <td>10373</td>\n",
       "      <td>[[215987 2, 1941-12-02, 9999-12-31], [215987 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[], [], [1990-04-01, 2015-07-18], [1990-04-01...</td>\n",
       "      <td>ST FRANCIS</td>\n",
       "      <td>[-93.3591, 45.3878]</td>\n",
       "      <td>[217309 2, USC00217309 6, SFSM5 7]</td>\n",
       "      <td>27003</td>\n",
       "      <td>MN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>MN06</td>\n",
       "      <td>10674</td>\n",
       "      <td>[[217309 2, 1990-03-01, 2013-09-01], [USC00217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1943-05-01, 2022-05-17], [1943-02-06, 2022-0...</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>[-93.09798, 44.71673]</td>\n",
       "      <td>[217107 2, USC00217107 6, RSMM5 7]</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>945.0</td>\n",
       "      <td>MN09</td>\n",
       "      <td>10395</td>\n",
       "      <td>[[217107 2, 1950-12-01, 9999-12-31], [217107 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[1892-04-25, 2022-05-16], [1892-04-26, 2022-0...</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>[-93.17559, 44.666]</td>\n",
       "      <td>[212737 2, USC00212737 6, FRMM5 7]</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>960.0</td>\n",
       "      <td>MN09</td>\n",
       "      <td>10392</td>\n",
       "      <td>[[212737 2, 2020-11-18, 9999-12-31], [212737 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[2002-09-01, 2013-04-28], [2002-09-01, 2013-0...</td>\n",
       "      <td>SPRING PARK</td>\n",
       "      <td>[-93.6275, 44.9346]</td>\n",
       "      <td>[217935 2, USC00217935 6, SPKM5 7]</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>MN06</td>\n",
       "      <td>31444</td>\n",
       "      <td>[[217935 2, 2000-07-25, 2013-05-01], [USC00217...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     valid_daterange  \\\n",
       "0  [[1893-01-01, 1893-05-31], [1893-01-01, 1893-0...   \n",
       "1  [[], [], [1990-04-01, 2015-07-18], [1990-04-01...   \n",
       "2  [[1943-05-01, 2022-05-17], [1943-02-06, 2022-0...   \n",
       "3  [[1892-04-25, 2022-05-16], [1892-04-26, 2022-0...   \n",
       "4  [[2002-09-01, 2013-04-28], [2002-09-01, 2013-0...   \n",
       "\n",
       "                                     name                     ll  \\\n",
       "0                         NORTHFIELD 2NNE    [-93.1486, 44.4753]   \n",
       "1                              ST FRANCIS    [-93.3591, 45.3878]   \n",
       "2  ROSEMOUNT RESEARCH AND OUTREACH CENTER  [-93.09798, 44.71673]   \n",
       "3                          FARMINGTON 3NW    [-93.17559, 44.666]   \n",
       "4                             SPRING PARK    [-93.6275, 44.9346]   \n",
       "\n",
       "                                          sids county state    elev climdiv  \\\n",
       "0  [215987 2, USC00215987 6, NFDM5 7, NRFM5 7]  27037    MN   890.0    MN08   \n",
       "1           [217309 2, USC00217309 6, SFSM5 7]  27003    MN   900.0    MN06   \n",
       "2           [217107 2, USC00217107 6, RSMM5 7]  27037    MN   945.0    MN09   \n",
       "3           [212737 2, USC00212737 6, FRMM5 7]  27037    MN   960.0    MN09   \n",
       "4           [217935 2, USC00217935 6, SPKM5 7]  27053    MN  1016.0    MN06   \n",
       "\n",
       "     uid                                          sid_dates  \n",
       "0  10373  [[215987 2, 1941-12-02, 9999-12-31], [215987 2...  \n",
       "1  10674  [[217309 2, 1990-03-01, 2013-09-01], [USC00217...  \n",
       "2  10395  [[217107 2, 1950-12-01, 9999-12-31], [217107 2...  \n",
       "3  10392  [[212737 2, 2020-11-18, 9999-12-31], [212737 2...  \n",
       "4  31444  [[217935 2, 2000-07-25, 2013-05-01], [USC00217...  "
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the ll list into Latitude and longitude \n",
    "split_df = pd.DataFrame(stations_df['ll'].to_list(), columns = ['latitude','longitude'])\n",
    "# concat df and split_df\n",
    "stations_df = pd.concat([stations_df, split_df], axis=1)\n",
    "# Drop ll column.\n",
    "stations_df = stations_df.drop(columns=[\"ll\"])\n",
    "# # display df\n",
    "# stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sids columns for the array sids\n",
    "sids = []\n",
    "sid_string = \"\"\n",
    "counter = 1\n",
    "for x in range(stations_df.sids.map(len).max()):\n",
    "  sids.append(f\"sid_{counter}\")\n",
    "  sid_string = f\"{sid_string}, 'sid_{counter}'\"\n",
    "  counter = counter + 1\n",
    "\n",
    "# split the array into separate columns\n",
    "split_df = pd.DataFrame(stations_df['sids'].to_list(), columns = sids)\n",
    "\n",
    "# concat df and split_df\n",
    "stations_df = pd.concat([stations_df, split_df], axis=1)\n",
    "\n",
    "# Drop names from columns.\n",
    "stations_df = stations_df.drop(columns=[\"sids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns in the DF - Remove the valid_daterange and sid_dates since they are not necessary\n",
    "column_list = f\"['uid','name','county','state','latitude','longitude','climdiv'{sid_string}]\"  #'valid_daterange','sid_dates'\n",
    "\n",
    "# change the string into an array for the reordering\n",
    "columnArray = literal_eval(column_list)\n",
    "\n",
    "stations_df= stations_df.loc[:, columnArray]\n",
    "stations_df.rename(columns={'uid':'station_uid'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>climdiv</th>\n",
       "      <th>sid_1</th>\n",
       "      <th>sid_2</th>\n",
       "      <th>sid_3</th>\n",
       "      <th>sid_4</th>\n",
       "      <th>sid_5</th>\n",
       "      <th>sid_6</th>\n",
       "      <th>sid_7</th>\n",
       "      <th>sid_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10373</td>\n",
       "      <td>NORTHFIELD 2NNE</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.14860</td>\n",
       "      <td>44.47530</td>\n",
       "      <td>MN08</td>\n",
       "      <td>215987 2</td>\n",
       "      <td>USC00215987 6</td>\n",
       "      <td>NFDM5 7</td>\n",
       "      <td>NRFM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10674</td>\n",
       "      <td>ST FRANCIS</td>\n",
       "      <td>27003</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.35910</td>\n",
       "      <td>45.38780</td>\n",
       "      <td>MN06</td>\n",
       "      <td>217309 2</td>\n",
       "      <td>USC00217309 6</td>\n",
       "      <td>SFSM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10395</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.09798</td>\n",
       "      <td>44.71673</td>\n",
       "      <td>MN09</td>\n",
       "      <td>217107 2</td>\n",
       "      <td>USC00217107 6</td>\n",
       "      <td>RSMM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10392</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.17559</td>\n",
       "      <td>44.66600</td>\n",
       "      <td>MN09</td>\n",
       "      <td>212737 2</td>\n",
       "      <td>USC00212737 6</td>\n",
       "      <td>FRMM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31444</td>\n",
       "      <td>SPRING PARK</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.62750</td>\n",
       "      <td>44.93460</td>\n",
       "      <td>MN06</td>\n",
       "      <td>217935 2</td>\n",
       "      <td>USC00217935 6</td>\n",
       "      <td>SPKM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid                                    name county state  latitude  \\\n",
       "0        10373                         NORTHFIELD 2NNE  27037    MN -93.14860   \n",
       "1        10674                              ST FRANCIS  27003    MN -93.35910   \n",
       "2        10395  ROSEMOUNT RESEARCH AND OUTREACH CENTER  27037    MN -93.09798   \n",
       "3        10392                          FARMINGTON 3NW  27037    MN -93.17559   \n",
       "4        31444                             SPRING PARK  27053    MN -93.62750   \n",
       "\n",
       "   longitude climdiv     sid_1          sid_2    sid_3    sid_4 sid_5 sid_6  \\\n",
       "0   44.47530    MN08  215987 2  USC00215987 6  NFDM5 7  NRFM5 7  None  None   \n",
       "1   45.38780    MN06  217309 2  USC00217309 6  SFSM5 7     None  None  None   \n",
       "2   44.71673    MN09  217107 2  USC00217107 6  RSMM5 7     None  None  None   \n",
       "3   44.66600    MN09  212737 2  USC00212737 6  FRMM5 7     None  None  None   \n",
       "4   44.93460    MN06  217935 2  USC00217935 6  SPKM5 7     None  None  None   \n",
       "\n",
       "  sid_7 sid_8  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  "
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data columns into the elems requested\n",
    "# create sids columns for the array sids\n",
    "elems = str(params_df[\"elems\"][0])\n",
    "\n",
    "elems = elems.replace(\",\",\"','\")\n",
    "\n",
    "# convert the elems from the params list to a string for splitting apart the Array \n",
    "column_list = f\"['{elems}']\"\n",
    "columnArray = literal_eval(column_list)\n",
    "\n",
    "# split the array into separate columns]\n",
    "split_df = pd.DataFrame(observations_df['data'].to_list(), columns = columnArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any of the \"M\" values with NaN in the data.  This is a Missing Value\n",
    "split_df.replace(\"M\",np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up the data returned based on the Elements stored in the params json file\n",
    "\n",
    "# concat df and split_df\n",
    "observations_df = pd.concat([observations_df, split_df], axis=1)\n",
    "# Drop data column.\n",
    "observations_df = observations_df.drop(columns=[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    3266599\n",
       "date           3266599\n",
       "maxt            126519\n",
       "mint            126458\n",
       "pcpn            525180\n",
       "snow            325993\n",
       "snwd            135178\n",
       "avgt            126064\n",
       "dtype: int64"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any observations where it's missing a min temperature\n",
    "observations_df = observations_df.dropna(subset=['mint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    126458\n",
       "date           126458\n",
       "maxt           126064\n",
       "mint           126458\n",
       "pcpn           115504\n",
       "snow            91125\n",
       "snwd            85397\n",
       "avgt           126064\n",
       "dtype: int64"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the datatypes of the columns to numeric\n",
    "observations_df[columnArray] = observations_df[columnArray].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    439\n",
       "name           439\n",
       "county         439\n",
       "state          439\n",
       "latitude       439\n",
       "longitude      439\n",
       "climdiv        439\n",
       "sid_1          439\n",
       "sid_2          438\n",
       "sid_3           29\n",
       "sid_4            9\n",
       "sid_5            5\n",
       "sid_6            4\n",
       "sid_7            2\n",
       "sid_8            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = stations_df[stations_df.station_uid.isin(observations_df['station_uid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    27\n",
       "name           27\n",
       "county         27\n",
       "state          27\n",
       "latitude       27\n",
       "longitude      27\n",
       "climdiv        27\n",
       "sid_1          27\n",
       "sid_2          26\n",
       "sid_3          25\n",
       "sid_4           8\n",
       "sid_5           5\n",
       "sid_6           4\n",
       "sid_7           2\n",
       "sid_8           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a freeze_day column based on min temperature\n",
    "observations_df['freeze_day'] = np.where(observations_df['mint'] <= 32, 1, 0)\n",
    "\n",
    "# Flag if it reaches above freezing on the day\n",
    "observations_df['above_freezing'] = np.where(observations_df['maxt'] > 32, 1, 0)\n",
    "\n",
    "# Create columns for the different date parts to make processing easier\n",
    "observations_df['obs_year'] = pd.to_datetime(observations_df['date']).dt.year\n",
    "observations_df['obs_month'] = pd.to_datetime(observations_df['date']).dt.month\n",
    "observations_df['obs_day'] = pd.to_datetime(observations_df['date']).dt.day\n",
    "observations_df['obs_dayofyear'] = pd.to_datetime(observations_df['date']).dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to store yearly summary info by station ID\n",
    "years = pd.to_datetime(observations_df['date']).dt.year.unique()\n",
    "years_df = pd.DataFrame(years,columns=['year'])\n",
    "station_yearly_metrics_df = pd.merge(stations_df['station_uid'], years_df, how='cross')\n",
    "station_yearly_metrics_df.set_index(['station_uid','year'])\n",
    "\n",
    "\n",
    "# get the last frost date of each station for each year of data\n",
    "last_freeze_df = observations_df.loc[(observations_df['freeze_day']==1)  & (observations_df['obs_dayofyear'] < 180),['station_uid','date','obs_year','obs_dayofyear'] ]. \\\n",
    "        groupby([\"station_uid\",\"obs_year\"])[['date','obs_dayofyear']].max().rename(columns={'date':'last_freeze_date','obs_dayofyear':'last_freeze_dayofyear'})\n",
    "#last_freeze_df.rename(columns={'date':'last_freeze_date','obs_dayofyear':'last_freeze_dayofyear'},inplace=True)\n",
    "\n",
    "# get the first freeze in the fall\n",
    "first_freeze_df = observations_df.loc[(observations_df['freeze_day']==1)  & (observations_df['obs_dayofyear'] >= 180),['station_uid','date','obs_year','obs_dayofyear'] ]. \\\n",
    "        groupby([\"station_uid\",\"obs_year\"])[['date','obs_dayofyear']].min().rename(columns={'date':'first_freeze_date','obs_dayofyear':'first_freeze_dayofyear'})\n",
    "# first_freeze_df.rename(columns={'date':'first_freeze_date','obs_dayofyear':'first_freeze_dayofyear'},inplace=True)\n",
    "\n",
    "# Determine if we have a complete set of observations for april to may for each station/year\n",
    "april_to_may_days_recorderd_df = pd.DataFrame(observations_df.loc[(observations_df['obs_month']>=4 )&(observations_df['obs_month'] <= 6),['station_uid','obs_year','mint']]\\\n",
    "        .groupby(['station_uid','obs_year'])['mint'].count()).rename(columns={'mint':'observations_recorded_april_to_may'})\n",
    "# april_to_may_days_recorderd_df.rename(columns={'mint':'observations_recorded_april_to_may'},inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the yearly data \n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, last_freeze_df, how='left', left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, first_freeze_df, how='left', left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, april_to_may_days_recorderd_df, left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean/average last freeze date for a station \n",
    "avg_last_freeze_df = pd.DataFrame(station_yearly_metrics_df.groupby(['station_uid'])['last_freeze_dayofyear'].mean().round(0)).rename(columns={'last_freeze_dayofyear':'avg_last_freeze_dayofyear'})\n",
    "# Convert the day of year to a string value for mm/dd\n",
    "avg_last_freeze_df[\"avg_last_freeze_mm_dd\"] = pd.to_datetime(avg_last_freeze_df[\"avg_last_freeze_dayofyear\"],format='%j').dt.strftime('%m/%d')\n",
    "\n",
    "# determine the mean, get the string value\n",
    "median_last_freeze_df = pd.DataFrame(station_yearly_metrics_df.groupby(['station_uid'])['last_freeze_dayofyear'].median().round(0)).rename(columns={'last_freeze_dayofyear':'median_last_freeze_dayofyear'})\n",
    "median_last_freeze_df[\"median_last_freeze_mm_dd\"] = pd.to_datetime(median_last_freeze_df[\"median_last_freeze_dayofyear\"],format='%j').dt.strftime('%m/%d')\n",
    "\n",
    "# Merge the values into a single table\n",
    "station_metrics_df = pd.merge(stations_df, avg_last_freeze_df, left_on=['station_uid'], right_on = ['station_uid'])\n",
    "station_metrics_df = pd.merge(station_metrics_df, median_last_freeze_df, left_on=['station_uid'], right_on = ['station_uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_station_and_yearly_df = pd.merge(station_metrics_df, station_yearly_metrics_df, how=\"left\", on=[\"station_uid\", \"station_uid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_years_count = merged_station_and_yearly_df.groupby(\"station_uid\").count()[\"year\"]\n",
    "\n",
    "# Calculate the number of years where the last freeze was before or on the average date\n",
    "stations_count_at_or_before_avg_last_freeze = merged_station_and_yearly_df[(merged_station_and_yearly_df[\"last_freeze_dayofyear\"] <= merged_station_and_yearly_df['avg_last_freeze_dayofyear'])]\n",
    "stations_count_at_or_before_avg_last_freeze = stations_count_at_or_before_avg_last_freeze.groupby(\"station_uid\").count()[\"year\"]\n",
    "\n",
    "# Calculate the number of years where the last freeze was after the average date\n",
    "stations_count_later_than_avg_last_freeze = merged_station_and_yearly_df[(merged_station_and_yearly_df[\"last_freeze_dayofyear\"] > merged_station_and_yearly_df['avg_last_freeze_dayofyear'])]\n",
    "stations_count_later_than_avg_last_freeze = stations_count_later_than_avg_last_freeze.groupby(\"station_uid\").count()[\"year\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_included</th>\n",
       "      <th>count_at_or_before_avg_last_freeze</th>\n",
       "      <th>count_later_than_avg_last_freeze</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             years_included  count_at_or_before_avg_last_freeze  \\\n",
       "station_uid                                                       \n",
       "10392                    10                                 5.0   \n",
       "10393                    20                                 7.0   \n",
       "10395                    21                                10.0   \n",
       "10398                    21                                12.0   \n",
       "10401                     1                                 1.0   \n",
       "\n",
       "             count_later_than_avg_last_freeze  \n",
       "station_uid                                    \n",
       "10392                                     5.0  \n",
       "10393                                    13.0  \n",
       "10395                                    11.0  \n",
       "10398                                     9.0  \n",
       "10401                                     NaN  "
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_calc_values_df = pd.DataFrame(\n",
    "          {\"years_included\": stations_years_count,\n",
    "          \"count_at_or_before_avg_last_freeze\": stations_count_at_or_before_avg_last_freeze, \n",
    "          \"count_later_than_avg_last_freeze\": stations_count_later_than_avg_last_freeze})\n",
    "station_calc_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>climdiv</th>\n",
       "      <th>sid_1</th>\n",
       "      <th>sid_2</th>\n",
       "      <th>sid_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sid_6</th>\n",
       "      <th>sid_7</th>\n",
       "      <th>sid_8</th>\n",
       "      <th>avg_last_freeze_dayofyear</th>\n",
       "      <th>avg_last_freeze_mm_dd</th>\n",
       "      <th>median_last_freeze_dayofyear</th>\n",
       "      <th>median_last_freeze_mm_dd</th>\n",
       "      <th>years_included</th>\n",
       "      <th>count_at_or_before_avg_last_freeze</th>\n",
       "      <th>count_later_than_avg_last_freeze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10395</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.09798</td>\n",
       "      <td>44.71673</td>\n",
       "      <td>MN09</td>\n",
       "      <td>217107 2</td>\n",
       "      <td>USC00217107 6</td>\n",
       "      <td>RSMM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>122.0</td>\n",
       "      <td>05/02</td>\n",
       "      <td>123.0</td>\n",
       "      <td>05/03</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10392</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.17559</td>\n",
       "      <td>44.66600</td>\n",
       "      <td>MN09</td>\n",
       "      <td>212737 2</td>\n",
       "      <td>USC00212737 6</td>\n",
       "      <td>FRMM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>117.0</td>\n",
       "      <td>04/27</td>\n",
       "      <td>118.0</td>\n",
       "      <td>04/28</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31444</td>\n",
       "      <td>SPRING PARK</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.62750</td>\n",
       "      <td>44.93460</td>\n",
       "      <td>MN06</td>\n",
       "      <td>217935 2</td>\n",
       "      <td>USC00217935 6</td>\n",
       "      <td>SPKM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>108.0</td>\n",
       "      <td>04/18</td>\n",
       "      <td>104.0</td>\n",
       "      <td>04/14</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10398</td>\n",
       "      <td>HASTINGS DAM 2</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-92.86890</td>\n",
       "      <td>44.75970</td>\n",
       "      <td>MN09</td>\n",
       "      <td>213567 2</td>\n",
       "      <td>USC00213567 6</td>\n",
       "      <td>HSTM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>109.0</td>\n",
       "      <td>04/19</td>\n",
       "      <td>108.0</td>\n",
       "      <td>04/18</td>\n",
       "      <td>21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10676</td>\n",
       "      <td>MOUND</td>\n",
       "      <td>27053</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.65000</td>\n",
       "      <td>44.95000</td>\n",
       "      <td>MN06</td>\n",
       "      <td>215665 2</td>\n",
       "      <td>USC00215665 6</td>\n",
       "      <td>MOUM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>117.0</td>\n",
       "      <td>04/27</td>\n",
       "      <td>117.0</td>\n",
       "      <td>04/27</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid                                    name county state  latitude  \\\n",
       "0        10395  ROSEMOUNT RESEARCH AND OUTREACH CENTER  27037    MN -93.09798   \n",
       "1        10392                          FARMINGTON 3NW  27037    MN -93.17559   \n",
       "2        31444                             SPRING PARK  27053    MN -93.62750   \n",
       "3        10398                          HASTINGS DAM 2  27037    MN -92.86890   \n",
       "4        10676                                   MOUND  27053    MN -93.65000   \n",
       "\n",
       "   longitude climdiv     sid_1          sid_2    sid_3  ... sid_6 sid_7 sid_8  \\\n",
       "0   44.71673    MN09  217107 2  USC00217107 6  RSMM5 7  ...  None  None  None   \n",
       "1   44.66600    MN09  212737 2  USC00212737 6  FRMM5 7  ...  None  None  None   \n",
       "2   44.93460    MN06  217935 2  USC00217935 6  SPKM5 7  ...  None  None  None   \n",
       "3   44.75970    MN09  213567 2  USC00213567 6  HSTM5 7  ...  None  None  None   \n",
       "4   44.95000    MN06  215665 2  USC00215665 6  MOUM5 7  ...  None  None  None   \n",
       "\n",
       "  avg_last_freeze_dayofyear avg_last_freeze_mm_dd  \\\n",
       "0                     122.0                 05/02   \n",
       "1                     117.0                 04/27   \n",
       "2                     108.0                 04/18   \n",
       "3                     109.0                 04/19   \n",
       "4                     117.0                 04/27   \n",
       "\n",
       "   median_last_freeze_dayofyear median_last_freeze_mm_dd  years_included  \\\n",
       "0                         123.0                    05/03              21   \n",
       "1                         118.0                    04/28              10   \n",
       "2                         104.0                    04/14              11   \n",
       "3                         108.0                    04/18              21   \n",
       "4                         117.0                    04/27               2   \n",
       "\n",
       "  count_at_or_before_avg_last_freeze  count_later_than_avg_last_freeze  \n",
       "0                               10.0                              11.0  \n",
       "1                                5.0                               5.0  \n",
       "2                                7.0                               4.0  \n",
       "3                               12.0                               9.0  \n",
       "4                                1.0                               1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_metrics_full_df = pd.merge(station_metrics_df, station_calc_values_df, how=\"left\", on=[\"station_uid\", \"station_uid\"])\n",
    "station_metrics_full_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Output file (CSV\n",
    "output_station_file = \"../Resources/station_df.csv\"\n",
    "output_station_year_file = \"../Resources/station_year_data.csv\"\n",
    "output_observation_file = \"../Resources/observation_data.csv\"\n",
    "\n",
    "station_metrics_full_df.to_csv(output_station_file, index=False)\n",
    "station_yearly_metrics_df.to_csv(output_station_year_file, index=False)\n",
    "observations_df.to_csv(output_observation_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to PostgreSQL movie_data DB\n",
    "# db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/last_freeze_analysis\"\n",
    "\n",
    "# # Create the database engine with the following line \n",
    "# engine = create_engine(db_string)\n",
    "\n",
    "# # Save the stations DataFrame to a SQL table \"stations\"- Replace the table if it already exists\n",
    "# stations_df.to_sql(name='stations', con=engine, if_exists='replace')   \n",
    "\n",
    "# # Save the observations DataFrame to a SQL table \"observations\"- Replace the table if it already exists\n",
    "# observations_df.to_sql(name='observations', con=engine, if_exists='replace')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a CSV file"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79cce83be72e55c1187b298660b26fa831a7f54746f9fd5c4205698cac5dca1a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
