{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "import time\n",
    "\n",
    "from config import db_password "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and import our 2 files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"Resources\"\n",
    "# Observation data\n",
    "weather_file = f'../{file_dir}/rcc_data.json'\n",
    "\n",
    "#Parameter File\n",
    "params_file = f'../{file_dir}/params_list.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the read the Observation data JSON file.\n",
    "with open(f'{weather_file}', mode='r') as file:\n",
    "    weather_raw = json.load(file)  # Load the file into a list of Dictionaries NOT RIGHT TO JSON\n",
    "\n",
    "with open(f'{params_file}', mode='r') as file:\n",
    "    params_data = json.load(file)  # Load the file into a list of Dictionaries NOT RIGHT TO JSON\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(weather_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the API parameters we used into a dataframe\n",
    "# We need the parameters to know the date range and the values in the observation Array\n",
    "params_df = pd.DataFrame(params_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse out the JSON data into a Stations Dataframe and an Observations Dataframe\n",
    "counter = 0\n",
    "stations_list =[]\n",
    "observations_list = []\n",
    "\n",
    "# Convert the start/end date used in the API call stored in the params file\n",
    "startDate = pd.to_datetime(params_df['sdate'][0])\n",
    "endDate = pd.to_datetime(params_df['edate'][0])\n",
    "\n",
    "# Loop through the upper most level of the JSON file called \"data\"\n",
    "for observation in weather_raw['data']:\n",
    "\n",
    "    # Create a list of stations\n",
    "    stations_list.append(observation[\"meta\"])\n",
    "        \n",
    "    # Start the current date at the first date in the range for each stations observations\n",
    "    currentDate = startDate\n",
    "    \n",
    "    # Loop through the stations observations and create a list of observations\n",
    "    for observation_data in observation[\"data\"]:\n",
    "        observations_list.append({\"station_uid\":observation[\"meta\"]['uid'],\"date\":currentDate, \"data\":observation_data})\n",
    "\n",
    "        # Increment the date by one day\n",
    "        currentDate = currentDate + timedelta(days=1)\n",
    "\n",
    "        # Increment our counter (for debugging use)\n",
    "        counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert our lists to dataframes\n",
    "stations_df = pd.DataFrame(stations_list)\n",
    "observations_df = pd.DataFrame(observations_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3266594</th>\n",
       "      <td>63155</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>[M, M, 0.96, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266595</th>\n",
       "      <td>63155</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>[M, M, 0.11, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266596</th>\n",
       "      <td>63155</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266597</th>\n",
       "      <td>63155</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266598</th>\n",
       "      <td>63155</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_uid       date                   data\n",
       "3266594        63155 2022-05-12  [M, M, 0.96, M, M, M]\n",
       "3266595        63155 2022-05-13  [M, M, 0.11, M, M, M]\n",
       "3266596        63155 2022-05-14     [M, M, M, M, M, M]\n",
       "3266597        63155 2022-05-15     [M, M, M, M, M, M]\n",
       "3266598        63155 2022-05-16     [M, M, M, M, M, M]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_daterange</th>\n",
       "      <th>name</th>\n",
       "      <th>ll</th>\n",
       "      <th>sids</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>elev</th>\n",
       "      <th>climdiv</th>\n",
       "      <th>uid</th>\n",
       "      <th>sid_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[1893-01-01, 1893-05-31], [1893-01-01, 1893-0...</td>\n",
       "      <td>NORTHFIELD 2NNE</td>\n",
       "      <td>[-93.1486, 44.4753]</td>\n",
       "      <td>[215987 2, USC00215987 6, NFDM5 7, NRFM5 7]</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>890.0</td>\n",
       "      <td>MN08</td>\n",
       "      <td>10373</td>\n",
       "      <td>[[215987 2, 1941-12-02, 9999-12-31], [215987 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[1892-04-25, 2022-05-24], [1892-04-26, 2022-0...</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>[-93.17559, 44.666]</td>\n",
       "      <td>[212737 2, USC00212737 6, FRMM5 7]</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>960.0</td>\n",
       "      <td>MN09</td>\n",
       "      <td>10392</td>\n",
       "      <td>[[212737 2, 2020-11-18, 9999-12-31], [212737 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1943-05-01, 2022-05-25], [1943-02-06, 2022-0...</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>[-93.09798, 44.71673]</td>\n",
       "      <td>[217107 2, USC00217107 6, RSMM5 7]</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>945.0</td>\n",
       "      <td>MN09</td>\n",
       "      <td>10395</td>\n",
       "      <td>[[217107 2, 1950-12-01, 9999-12-31], [217107 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[1949-01-01, 2022-05-20], [1943-09-01, 2022-0...</td>\n",
       "      <td>JORDAN 1SSW</td>\n",
       "      <td>[-93.6356, 44.6501]</td>\n",
       "      <td>[214176 2, USC00214176 6, JORM5 7, JDNM5 7]</td>\n",
       "      <td>27139</td>\n",
       "      <td>MN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>MN05</td>\n",
       "      <td>10393</td>\n",
       "      <td>[[214176 2, 2009-02-01, 9999-12-31], [214176 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1893-08-05, 2022-05-25], [1893-08-05, 2022-0...</td>\n",
       "      <td>HASTINGS DAM 2</td>\n",
       "      <td>[-92.8689, 44.7597]</td>\n",
       "      <td>[213567 2, USC00213567 6, HSTM5 7]</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>680.0</td>\n",
       "      <td>MN09</td>\n",
       "      <td>10398</td>\n",
       "      <td>[[213567 2, 1932-10-01, 9999-12-31], [213567 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     valid_daterange  \\\n",
       "0  [[1893-01-01, 1893-05-31], [1893-01-01, 1893-0...   \n",
       "1  [[1892-04-25, 2022-05-24], [1892-04-26, 2022-0...   \n",
       "2  [[1943-05-01, 2022-05-25], [1943-02-06, 2022-0...   \n",
       "3  [[1949-01-01, 2022-05-20], [1943-09-01, 2022-0...   \n",
       "4  [[1893-08-05, 2022-05-25], [1893-08-05, 2022-0...   \n",
       "\n",
       "                                     name                     ll  \\\n",
       "0                         NORTHFIELD 2NNE    [-93.1486, 44.4753]   \n",
       "1                          FARMINGTON 3NW    [-93.17559, 44.666]   \n",
       "2  ROSEMOUNT RESEARCH AND OUTREACH CENTER  [-93.09798, 44.71673]   \n",
       "3                             JORDAN 1SSW    [-93.6356, 44.6501]   \n",
       "4                          HASTINGS DAM 2    [-92.8689, 44.7597]   \n",
       "\n",
       "                                          sids county state   elev climdiv  \\\n",
       "0  [215987 2, USC00215987 6, NFDM5 7, NRFM5 7]  27037    MN  890.0    MN08   \n",
       "1           [212737 2, USC00212737 6, FRMM5 7]  27037    MN  960.0    MN09   \n",
       "2           [217107 2, USC00217107 6, RSMM5 7]  27037    MN  945.0    MN09   \n",
       "3  [214176 2, USC00214176 6, JORM5 7, JDNM5 7]  27139    MN  900.0    MN05   \n",
       "4           [213567 2, USC00213567 6, HSTM5 7]  27037    MN  680.0    MN09   \n",
       "\n",
       "     uid                                          sid_dates  \n",
       "0  10373  [[215987 2, 1941-12-02, 9999-12-31], [215987 2...  \n",
       "1  10392  [[212737 2, 2020-11-18, 9999-12-31], [212737 2...  \n",
       "2  10395  [[217107 2, 1950-12-01, 9999-12-31], [217107 2...  \n",
       "3  10393  [[214176 2, 2009-02-01, 9999-12-31], [214176 2...  \n",
       "4  10398  [[213567 2, 1932-10-01, 9999-12-31], [213567 2...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the ll list into Latitude and longitude \n",
    "split_df = pd.DataFrame(stations_df['ll'].to_list(), columns = ['latitude','longitude'])\n",
    "# concat df and split_df\n",
    "stations_df = pd.concat([stations_df, split_df], axis=1)\n",
    "# Drop ll column.\n",
    "stations_df = stations_df.drop(columns=[\"ll\"])\n",
    "# # display df\n",
    "# stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sids columns for the array sids\n",
    "sids = []\n",
    "sid_string = \"\"\n",
    "counter = 1\n",
    "for x in range(stations_df.sids.map(len).max()):\n",
    "  sids.append(f\"sid_{counter}\")\n",
    "  sid_string = f\"{sid_string}, 'sid_{counter}'\"\n",
    "  counter = counter + 1\n",
    "\n",
    "# split the array into separate columns\n",
    "split_df = pd.DataFrame(stations_df['sids'].to_list(), columns = sids)\n",
    "\n",
    "# concat df and split_df\n",
    "stations_df = pd.concat([stations_df, split_df], axis=1)\n",
    "\n",
    "# Drop names from columns.\n",
    "stations_df = stations_df.drop(columns=[\"sids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns in the DF - Remove the valid_daterange and sid_dates since they are not necessary\n",
    "column_list = f\"['uid','name','county','state','latitude','longitude','climdiv'{sid_string}]\"  #'valid_daterange','sid_dates'\n",
    "\n",
    "# change the string into an array for the reordering\n",
    "columnArray = literal_eval(column_list)\n",
    "\n",
    "stations_df= stations_df.loc[:, columnArray]\n",
    "stations_df.rename(columns={'uid':'station_uid'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>climdiv</th>\n",
       "      <th>sid_1</th>\n",
       "      <th>sid_2</th>\n",
       "      <th>sid_3</th>\n",
       "      <th>sid_4</th>\n",
       "      <th>sid_5</th>\n",
       "      <th>sid_6</th>\n",
       "      <th>sid_7</th>\n",
       "      <th>sid_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10373</td>\n",
       "      <td>NORTHFIELD 2NNE</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.14860</td>\n",
       "      <td>44.47530</td>\n",
       "      <td>MN08</td>\n",
       "      <td>215987 2</td>\n",
       "      <td>USC00215987 6</td>\n",
       "      <td>NFDM5 7</td>\n",
       "      <td>NRFM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10392</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.17559</td>\n",
       "      <td>44.66600</td>\n",
       "      <td>MN09</td>\n",
       "      <td>212737 2</td>\n",
       "      <td>USC00212737 6</td>\n",
       "      <td>FRMM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10395</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.09798</td>\n",
       "      <td>44.71673</td>\n",
       "      <td>MN09</td>\n",
       "      <td>217107 2</td>\n",
       "      <td>USC00217107 6</td>\n",
       "      <td>RSMM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10393</td>\n",
       "      <td>JORDAN 1SSW</td>\n",
       "      <td>27139</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.63560</td>\n",
       "      <td>44.65010</td>\n",
       "      <td>MN05</td>\n",
       "      <td>214176 2</td>\n",
       "      <td>USC00214176 6</td>\n",
       "      <td>JORM5 7</td>\n",
       "      <td>JDNM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10398</td>\n",
       "      <td>HASTINGS DAM 2</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-92.86890</td>\n",
       "      <td>44.75970</td>\n",
       "      <td>MN09</td>\n",
       "      <td>213567 2</td>\n",
       "      <td>USC00213567 6</td>\n",
       "      <td>HSTM5 7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid                                    name county state  latitude  \\\n",
       "0        10373                         NORTHFIELD 2NNE  27037    MN -93.14860   \n",
       "1        10392                          FARMINGTON 3NW  27037    MN -93.17559   \n",
       "2        10395  ROSEMOUNT RESEARCH AND OUTREACH CENTER  27037    MN -93.09798   \n",
       "3        10393                             JORDAN 1SSW  27139    MN -93.63560   \n",
       "4        10398                          HASTINGS DAM 2  27037    MN -92.86890   \n",
       "\n",
       "   longitude climdiv     sid_1          sid_2    sid_3    sid_4 sid_5 sid_6  \\\n",
       "0   44.47530    MN08  215987 2  USC00215987 6  NFDM5 7  NRFM5 7  None  None   \n",
       "1   44.66600    MN09  212737 2  USC00212737 6  FRMM5 7     None  None  None   \n",
       "2   44.71673    MN09  217107 2  USC00217107 6  RSMM5 7     None  None  None   \n",
       "3   44.65010    MN05  214176 2  USC00214176 6  JORM5 7  JDNM5 7  None  None   \n",
       "4   44.75970    MN09  213567 2  USC00213567 6  HSTM5 7     None  None  None   \n",
       "\n",
       "  sid_7 sid_8  \n",
       "0  None  None  \n",
       "1  None  None  \n",
       "2  None  None  \n",
       "3  None  None  \n",
       "4  None  None  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the observations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-02</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-03</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-04</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10373</td>\n",
       "      <td>2002-01-05</td>\n",
       "      <td>[M, M, M, M, M, M]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid       date                data\n",
       "0        10373 2002-01-01  [M, M, M, M, M, M]\n",
       "1        10373 2002-01-02  [M, M, M, M, M, M]\n",
       "2        10373 2002-01-03  [M, M, M, M, M, M]\n",
       "3        10373 2002-01-04  [M, M, M, M, M, M]\n",
       "4        10373 2002-01-05  [M, M, M, M, M, M]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data columns into the elems requested\n",
    "elems = str(params_df[\"elems\"][0])\n",
    "\n",
    "elems = elems.replace(\",\",\"','\")\n",
    "\n",
    "# convert the elems from the params list to a string for splitting apart the Array \n",
    "column_list = f\"['{elems}']\"\n",
    "columnArray = literal_eval(column_list)\n",
    "\n",
    "# split the array into separate columns]\n",
    "split_df = pd.DataFrame(observations_df['data'].to_list(), columns = columnArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any of the \"M\" values with NaN in the data.  This is a Missing Value\n",
    "split_df.replace(\"M\",np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any of the \"T\" values with 0 in the data.  This is a trace amount of precipitation\n",
    "split_df.replace(\"T\",0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up the data returned based on the Elements stored in the params json file\n",
    "\n",
    "# concat df and split_df\n",
    "observations_df = pd.concat([observations_df, split_df], axis=1)\n",
    "# Drop data column.\n",
    "observations_df = observations_df.drop(columns=[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    3266599\n",
       "date           3266599\n",
       "maxt            126528\n",
       "mint            126467\n",
       "pcpn            525442\n",
       "snow            326223\n",
       "snwd            135202\n",
       "avgt            126073\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any observations where it's missing a min temperature\n",
    "observations_df = observations_df.dropna(subset=['mint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    126467\n",
       "date           126467\n",
       "maxt           126073\n",
       "mint           126467\n",
       "pcpn           115512\n",
       "snow            91141\n",
       "snwd            85409\n",
       "avgt           126073\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the datatypes of the columns to numeric\n",
    "observations_df[columnArray] = observations_df[columnArray].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    439\n",
       "name           439\n",
       "county         439\n",
       "state          439\n",
       "latitude       439\n",
       "longitude      439\n",
       "climdiv        439\n",
       "sid_1          439\n",
       "sid_2          438\n",
       "sid_3           29\n",
       "sid_4            9\n",
       "sid_5            5\n",
       "sid_6            4\n",
       "sid_7            2\n",
       "sid_8            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = stations_df[stations_df.station_uid.isin(observations_df['station_uid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_uid    27\n",
       "name           27\n",
       "county         27\n",
       "state          27\n",
       "latitude       27\n",
       "longitude      27\n",
       "climdiv        27\n",
       "sid_1          27\n",
       "sid_2          26\n",
       "sid_3          25\n",
       "sid_4           8\n",
       "sid_5           5\n",
       "sid_6           4\n",
       "sid_7           2\n",
       "sid_8           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create calculated fields for dashboard and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a freeze_day column based on min temperature\n",
    "observations_df['freeze_day'] = np.where(observations_df['mint'] <= 32, 1, 0)\n",
    "\n",
    "# Flag if it reaches above freezing on the day\n",
    "observations_df['above_freezing'] = np.where(observations_df['maxt'] > 32, 1, 0)\n",
    "\n",
    "# Create columns for the different date parts to make processing easier\n",
    "observations_df['obs_year'] = pd.to_datetime(observations_df['date']).dt.year\n",
    "observations_df['obs_month'] = pd.to_datetime(observations_df['date']).dt.month\n",
    "observations_df['obs_day'] = pd.to_datetime(observations_df['date']).dt.day\n",
    "observations_df['obs_dayofyear'] = pd.to_datetime(observations_df['date']).dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Station/Year dataframe creation and calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to store yearly summary info by station ID\n",
    "years = pd.to_datetime(observations_df['date']).dt.year.unique()\n",
    "years_df = pd.DataFrame(years,columns=['year'])\n",
    "station_yearly_metrics_df = pd.merge(stations_df['station_uid'], years_df, how='cross')\n",
    "station_yearly_metrics_df.set_index(['station_uid','year'])\n",
    "\n",
    "\n",
    "# get the last frost date of each station for each year of data\n",
    "last_freeze_df = observations_df.loc[(observations_df['freeze_day']==1)  & (observations_df['obs_dayofyear'] < 180),['station_uid','date','obs_year','obs_dayofyear'] ]. \\\n",
    "        groupby([\"station_uid\",\"obs_year\"])[['date','obs_dayofyear']].max().rename(columns={'date':'last_freeze_date','obs_dayofyear':'last_freeze_dayofyear'})\n",
    "\n",
    "# get the first freeze in the fall\n",
    "first_freeze_df = observations_df.loc[(observations_df['freeze_day']==1)  & (observations_df['obs_dayofyear'] >= 180),['station_uid','date','obs_year','obs_dayofyear'] ]. \\\n",
    "        groupby([\"station_uid\",\"obs_year\"])[['date','obs_dayofyear']].min().rename(columns={'date':'first_freeze_date','obs_dayofyear':'first_freeze_dayofyear'})\n",
    "\n",
    "# Determine if we have a complete set of observations for april to may for each station/year\n",
    "april_to_may_days_recorderd_df = pd.DataFrame(observations_df.loc[(observations_df['obs_month']>=4 )&(observations_df['obs_month'] <= 6),['station_uid','obs_year','mint']]\\\n",
    "        .groupby(['station_uid','obs_year'])['mint'].count()).rename(columns={'mint':'observations_recorded_april_to_may'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coldest day of the year\n",
    "coldest_day_of_year = observations_df.groupby([\"station_uid\",\"obs_year\"])[['mint']].min().rename(columns={'mint':'coldest_day'})\n",
    "coldest_day_df = pd.merge(coldest_day_of_year, observations_df, how='left', left_on=['station_uid', 'obs_year','coldest_day'], right_on = [\"station_uid\",\"obs_year\",\"mint\"])\n",
    "coldest_day_of_year_df = pd.DataFrame(coldest_day_df.groupby([\"station_uid\",\"obs_year\",'coldest_day'])['obs_dayofyear'].max())\n",
    "coldest_day_of_year_df.rename(columns={'obs_dayofyear':'coldest_dayofyear'},inplace=True)\n",
    "coldest_day_of_year_df = coldest_day_of_year_df.reset_index()\n",
    "coldest_day_of_year_df = coldest_day_of_year_df.set_index(keys=['station_uid','obs_year'])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, coldest_day_of_year_df, left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "#coldest_day_of_year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hottest day of the year, if there are multiple days with the temperature, use the latest one in the year (the one closest to the next last freeze date the next spring)\n",
    "hottest_day_of_year = observations_df.groupby([\"station_uid\",\"obs_year\"])[['maxt']].max().rename(columns={'maxt':'hottest_day'})\n",
    "hottest_day_df = pd.merge(hottest_day_of_year, observations_df, how='left', left_on=['station_uid', 'obs_year','hottest_day'], right_on = [\"station_uid\",\"obs_year\",\"maxt\"])\n",
    "hottest_day_of_year_df = pd.DataFrame(hottest_day_df.groupby([\"station_uid\",\"obs_year\",'hottest_day'])['obs_dayofyear'].max())\n",
    "hottest_day_of_year_df.rename(columns={'obs_dayofyear':'hottest_dayofyear'},inplace=True)\n",
    "hottest_day_of_year_df = hottest_day_of_year_df.reset_index()\n",
    "hottest_day_of_year_df = hottest_day_of_year_df.set_index(keys=['station_uid','obs_year'])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, hottest_day_of_year_df, left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "#hottest_day_of_year_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the yearly data \n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, last_freeze_df, how='left', left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, first_freeze_df, how='left', left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])\n",
    "station_yearly_metrics_df = pd.merge(station_yearly_metrics_df, april_to_may_days_recorderd_df, left_on=['station_uid', 'year'], right_on = [\"station_uid\",\"obs_year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>year</th>\n",
       "      <th>coldest_day</th>\n",
       "      <th>coldest_dayofyear</th>\n",
       "      <th>hottest_day</th>\n",
       "      <th>hottest_dayofyear</th>\n",
       "      <th>last_freeze_date</th>\n",
       "      <th>last_freeze_dayofyear</th>\n",
       "      <th>first_freeze_date</th>\n",
       "      <th>first_freeze_dayofyear</th>\n",
       "      <th>observations_recorded_april_to_may</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10392</td>\n",
       "      <td>2002</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>18</td>\n",
       "      <td>95.0</td>\n",
       "      <td>181</td>\n",
       "      <td>2002-05-05</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2002-10-07</td>\n",
       "      <td>280.0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10392</td>\n",
       "      <td>2003</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>38</td>\n",
       "      <td>94.0</td>\n",
       "      <td>236</td>\n",
       "      <td>2003-04-17</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10392</td>\n",
       "      <td>2005</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>14</td>\n",
       "      <td>92.0</td>\n",
       "      <td>197</td>\n",
       "      <td>2005-05-12</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>280.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10392</td>\n",
       "      <td>2006</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>49</td>\n",
       "      <td>97.0</td>\n",
       "      <td>212</td>\n",
       "      <td>2006-04-09</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>284.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10392</td>\n",
       "      <td>2007</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>36</td>\n",
       "      <td>94.0</td>\n",
       "      <td>207</td>\n",
       "      <td>2007-04-15</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2007-09-14</td>\n",
       "      <td>257.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid  year  coldest_day  coldest_dayofyear  hottest_day  \\\n",
       "0        10392  2002         -5.0                 18         95.0   \n",
       "1        10392  2003        -16.0                 38         94.0   \n",
       "2        10392  2005        -16.0                 14         92.0   \n",
       "3        10392  2006        -14.0                 49         97.0   \n",
       "4        10392  2007        -19.0                 36         94.0   \n",
       "\n",
       "   hottest_dayofyear last_freeze_date  last_freeze_dayofyear  \\\n",
       "0                181       2002-05-05                  125.0   \n",
       "1                236       2003-04-17                  107.0   \n",
       "2                197       2005-05-12                  132.0   \n",
       "3                212       2006-04-09                   99.0   \n",
       "4                207       2007-04-15                  105.0   \n",
       "\n",
       "  first_freeze_date  first_freeze_dayofyear  \\\n",
       "0        2002-10-07                   280.0   \n",
       "1               NaT                     NaN   \n",
       "2        2005-10-07                   280.0   \n",
       "3        2006-10-11                   284.0   \n",
       "4        2007-09-14                   257.0   \n",
       "\n",
       "   observations_recorded_april_to_may  \n",
       "0                                  91  \n",
       "1                                  91  \n",
       "2                                  87  \n",
       "3                                  85  \n",
       "4                                  90  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_yearly_metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of calculations for the Stations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the mean/average last freeze date for a station \n",
    "avg_last_freeze_df = pd.DataFrame(station_yearly_metrics_df.groupby(['station_uid'])['last_freeze_dayofyear'].mean().round(0)).rename(columns={'last_freeze_dayofyear':'avg_last_freeze_dayofyear'})\n",
    "\n",
    "# Convert the day of year to a string value for mm/dd\n",
    "avg_last_freeze_df[\"avg_last_freeze_mm_dd\"] = pd.to_datetime(avg_last_freeze_df[\"avg_last_freeze_dayofyear\"],format='%j').dt.strftime('%m/%d')\n",
    "\n",
    "# determine the mean, get the string value\n",
    "median_last_freeze_df = pd.DataFrame(station_yearly_metrics_df.groupby(['station_uid'])['last_freeze_dayofyear'].median().round(0)).rename(columns={'last_freeze_dayofyear':'median_last_freeze_dayofyear'})\n",
    "median_last_freeze_df[\"median_last_freeze_mm_dd\"] = pd.to_datetime(median_last_freeze_df[\"median_last_freeze_dayofyear\"],format='%j').dt.strftime('%m/%d')\n",
    "\n",
    "# Merge the values into a single table\n",
    "station_metrics_df = pd.merge(stations_df, avg_last_freeze_df, left_on=['station_uid'], right_on = ['station_uid'])\n",
    "station_metrics_df = pd.merge(station_metrics_df, median_last_freeze_df, left_on=['station_uid'], right_on = ['station_uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the station metrics and station/yearly DF to determine metrics for each station\n",
    "merged_station_and_yearly_df = pd.merge(station_metrics_df, station_yearly_metrics_df, how=\"left\", on=[\"station_uid\", \"station_uid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a count of how many years the station is in the dataset\n",
    "stations_years_count = merged_station_and_yearly_df.groupby(\"station_uid\").count()[\"year\"]\n",
    "\n",
    "# Calculate the number of years where the last freeze was before or on the average date\n",
    "stations_count_at_or_before_avg_last_freeze = merged_station_and_yearly_df[(merged_station_and_yearly_df[\"last_freeze_dayofyear\"] <= merged_station_and_yearly_df['avg_last_freeze_dayofyear'])]\n",
    "stations_count_at_or_before_avg_last_freeze = stations_count_at_or_before_avg_last_freeze.groupby(\"station_uid\").count()[\"year\"]\n",
    "\n",
    "# Calculate the number of years where the last freeze was after the average date\n",
    "stations_count_later_than_avg_last_freeze = merged_station_and_yearly_df[(merged_station_and_yearly_df[\"last_freeze_dayofyear\"] > merged_station_and_yearly_df['avg_last_freeze_dayofyear'])]\n",
    "stations_count_later_than_avg_last_freeze = stations_count_later_than_avg_last_freeze.groupby(\"station_uid\").count()[\"year\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years_included</th>\n",
       "      <th>count_at_or_before_avg_last_freeze</th>\n",
       "      <th>count_later_than_avg_last_freeze</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             years_included  count_at_or_before_avg_last_freeze  \\\n",
       "station_uid                                                       \n",
       "10392                    10                                 5.0   \n",
       "10393                    20                                 7.0   \n",
       "10395                    21                                10.0   \n",
       "10398                    21                                12.0   \n",
       "10401                     1                                 1.0   \n",
       "\n",
       "             count_later_than_avg_last_freeze  \n",
       "station_uid                                    \n",
       "10392                                     5.0  \n",
       "10393                                    13.0  \n",
       "10395                                    11.0  \n",
       "10398                                     9.0  \n",
       "10401                                     NaN  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_calc_values_df = pd.DataFrame(\n",
    "          {\"years_included\": stations_years_count,\n",
    "          \"count_at_or_before_avg_last_freeze\": stations_count_at_or_before_avg_last_freeze, \n",
    "          \"count_later_than_avg_last_freeze\": stations_count_later_than_avg_last_freeze})\n",
    "station_calc_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>climdiv</th>\n",
       "      <th>sid_1</th>\n",
       "      <th>sid_2</th>\n",
       "      <th>sid_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sid_6</th>\n",
       "      <th>sid_7</th>\n",
       "      <th>sid_8</th>\n",
       "      <th>avg_last_freeze_dayofyear</th>\n",
       "      <th>avg_last_freeze_mm_dd</th>\n",
       "      <th>median_last_freeze_dayofyear</th>\n",
       "      <th>median_last_freeze_mm_dd</th>\n",
       "      <th>years_included</th>\n",
       "      <th>count_at_or_before_avg_last_freeze</th>\n",
       "      <th>count_later_than_avg_last_freeze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10392</td>\n",
       "      <td>FARMINGTON 3NW</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.17559</td>\n",
       "      <td>44.66600</td>\n",
       "      <td>MN09</td>\n",
       "      <td>212737 2</td>\n",
       "      <td>USC00212737 6</td>\n",
       "      <td>FRMM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>117.0</td>\n",
       "      <td>04/27</td>\n",
       "      <td>118.0</td>\n",
       "      <td>04/28</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10395</td>\n",
       "      <td>ROSEMOUNT RESEARCH AND OUTREACH CENTER</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.09798</td>\n",
       "      <td>44.71673</td>\n",
       "      <td>MN09</td>\n",
       "      <td>217107 2</td>\n",
       "      <td>USC00217107 6</td>\n",
       "      <td>RSMM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>122.0</td>\n",
       "      <td>05/02</td>\n",
       "      <td>123.0</td>\n",
       "      <td>05/03</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10393</td>\n",
       "      <td>JORDAN 1SSW</td>\n",
       "      <td>27139</td>\n",
       "      <td>MN</td>\n",
       "      <td>-93.63560</td>\n",
       "      <td>44.65010</td>\n",
       "      <td>MN05</td>\n",
       "      <td>214176 2</td>\n",
       "      <td>USC00214176 6</td>\n",
       "      <td>JORM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>118.0</td>\n",
       "      <td>04/28</td>\n",
       "      <td>122.0</td>\n",
       "      <td>05/02</td>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10398</td>\n",
       "      <td>HASTINGS DAM 2</td>\n",
       "      <td>27037</td>\n",
       "      <td>MN</td>\n",
       "      <td>-92.86890</td>\n",
       "      <td>44.75970</td>\n",
       "      <td>MN09</td>\n",
       "      <td>213567 2</td>\n",
       "      <td>USC00213567 6</td>\n",
       "      <td>HSTM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>109.0</td>\n",
       "      <td>04/19</td>\n",
       "      <td>108.0</td>\n",
       "      <td>04/18</td>\n",
       "      <td>21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10401</td>\n",
       "      <td>YOUNG AMERICA 1SW</td>\n",
       "      <td>27019</td>\n",
       "      <td>MN</td>\n",
       "      <td>-94.01667</td>\n",
       "      <td>44.80556</td>\n",
       "      <td>MN05</td>\n",
       "      <td>219208 2</td>\n",
       "      <td>USC00219208 6</td>\n",
       "      <td>YNGM5 7</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>108.0</td>\n",
       "      <td>04/18</td>\n",
       "      <td>108.0</td>\n",
       "      <td>04/18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_uid                                    name county state  latitude  \\\n",
       "0        10392                          FARMINGTON 3NW  27037    MN -93.17559   \n",
       "1        10395  ROSEMOUNT RESEARCH AND OUTREACH CENTER  27037    MN -93.09798   \n",
       "2        10393                             JORDAN 1SSW  27139    MN -93.63560   \n",
       "3        10398                          HASTINGS DAM 2  27037    MN -92.86890   \n",
       "4        10401                       YOUNG AMERICA 1SW  27019    MN -94.01667   \n",
       "\n",
       "   longitude climdiv     sid_1          sid_2    sid_3  ... sid_6 sid_7 sid_8  \\\n",
       "0   44.66600    MN09  212737 2  USC00212737 6  FRMM5 7  ...  None  None  None   \n",
       "1   44.71673    MN09  217107 2  USC00217107 6  RSMM5 7  ...  None  None  None   \n",
       "2   44.65010    MN05  214176 2  USC00214176 6  JORM5 7  ...  None  None  None   \n",
       "3   44.75970    MN09  213567 2  USC00213567 6  HSTM5 7  ...  None  None  None   \n",
       "4   44.80556    MN05  219208 2  USC00219208 6  YNGM5 7  ...  None  None  None   \n",
       "\n",
       "  avg_last_freeze_dayofyear avg_last_freeze_mm_dd  \\\n",
       "0                     117.0                 04/27   \n",
       "1                     122.0                 05/02   \n",
       "2                     118.0                 04/28   \n",
       "3                     109.0                 04/19   \n",
       "4                     108.0                 04/18   \n",
       "\n",
       "   median_last_freeze_dayofyear median_last_freeze_mm_dd  years_included  \\\n",
       "0                         118.0                    04/28              10   \n",
       "1                         123.0                    05/03              21   \n",
       "2                         122.0                    05/02              20   \n",
       "3                         108.0                    04/18              21   \n",
       "4                         108.0                    04/18               1   \n",
       "\n",
       "  count_at_or_before_avg_last_freeze  count_later_than_avg_last_freeze  \n",
       "0                                5.0                               5.0  \n",
       "1                               10.0                              11.0  \n",
       "2                                7.0                              13.0  \n",
       "3                               12.0                               9.0  \n",
       "4                                1.0                               NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_metrics_full_df = pd.merge(station_metrics_df, station_calc_values_df, how=\"left\", on=[\"station_uid\", \"station_uid\"])\n",
    "station_metrics_full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Observation Day Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_uid</th>\n",
       "      <th>date</th>\n",
       "      <th>maxt</th>\n",
       "      <th>mint</th>\n",
       "      <th>pcpn</th>\n",
       "      <th>snow</th>\n",
       "      <th>snwd</th>\n",
       "      <th>avgt</th>\n",
       "      <th>freeze_day</th>\n",
       "      <th>above_freezing</th>\n",
       "      <th>obs_year</th>\n",
       "      <th>obs_month</th>\n",
       "      <th>obs_day</th>\n",
       "      <th>obs_dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>10392</td>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7442</th>\n",
       "      <td>10392</td>\n",
       "      <td>2002-01-02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>10392</td>\n",
       "      <td>2002-01-03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>10392</td>\n",
       "      <td>2002-01-04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>10392</td>\n",
       "      <td>2002-01-05</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_uid       date  maxt  mint  pcpn  snow  snwd  avgt  freeze_day  \\\n",
       "7441        10392 2002-01-01  15.0   6.0   0.0   0.0   2.0  10.5           1   \n",
       "7442        10392 2002-01-02  16.0  -2.0   0.0   0.0   NaN   7.0           1   \n",
       "7443        10392 2002-01-03  25.0  -0.0   0.0   0.0   2.0  12.5           1   \n",
       "7444        10392 2002-01-04  32.0  18.0   0.0   0.0   NaN  25.0           1   \n",
       "7445        10392 2002-01-05  34.0  27.0   0.0   0.0   NaN  30.5           1   \n",
       "\n",
       "      above_freezing  obs_year  obs_month  obs_day  obs_dayofyear  \n",
       "7441               0      2002          1        1              1  \n",
       "7442               0      2002          1        2              2  \n",
       "7443               0      2002          1        3              3  \n",
       "7444               0      2002          1        4              4  \n",
       "7445               1      2002          1        5              5  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation_calcs_loop(date_range):\n",
    "    counter = 0\n",
    "    observation_calcs_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through all the observations and calculate the metrics based on the number of days previous passed in\n",
    "    for index, row in observations_df.iterrows():\n",
    "        # call function to get previous X days of data\n",
    "\n",
    "        df = pd.DataFrame(observations_df.loc[(observations_df.station_uid == row['station_uid']) & \\\n",
    "                            (observations_df.date < row['date']) & \\\n",
    "                            (observations_df.date >= row['date'] - timedelta(days=date_range))] \\\n",
    "                    .groupby('station_uid').agg(max_temp=('maxt', 'max'), \n",
    "                            min_temp=('mint', 'min'),\n",
    "                            avgt=('avgt','mean'),\n",
    "                            precip=('pcpn','sum'),\n",
    "                            count=('date','count')) \\\n",
    "                    .reset_index(drop=True))\n",
    "\n",
    "        df['source_index'] = index\n",
    "\n",
    "        observation_calcs_df = pd.concat([observation_calcs_df,df], ignore_index=True)\n",
    "        \n",
    "    # Rename the columns for the range\n",
    "    column_array = [f'maxt_{date_range}_day', f'mint_{date_range}_day', f'avgt_{date_range}_day', f'precip_{date_range}_day',f'obs_count_{date_range}_day','source_index']\n",
    "    observation_calcs_df.columns = column_array\n",
    "\n",
    "    observation_calcs_df = observation_calcs_df.set_index(\"source_index\")\n",
    "    return observation_calcs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function for 7 days and merge the new columns into the table\n",
    "observations_calcs_7_day = observation_calcs_loop(7)\n",
    "observations_new_df = pd.merge(observations_df, observations_calcs_7_day, how=\"left\", left_index=True, right_index=True)\n",
    "# observations_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function for 30 days and merge the new columns into the table\n",
    "observations_calcs_30_day = observation_calcs_loop(30)\n",
    "observations_new_df = pd.merge(observations_new_df, observations_calcs_30_day, how=\"left\", left_index=True, right_index=True)\n",
    "# observations_new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED TO ADD\n",
    "# days_from avg\n",
    "# days from actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Output file (CSV\n",
    "output_station_file = \"../Resources/station_data.csv\"\n",
    "output_station_year_file = \"../Resources/station_year_data.csv\"\n",
    "output_observation_file = \"../Resources/observation_data.csv\"\n",
    "\n",
    "station_metrics_full_df.to_csv(output_station_file, index=False)\n",
    "station_yearly_metrics_df.to_csv(output_station_year_file, index=False)\n",
    "observations_new_df.to_csv(output_observation_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL movie_data DB\n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/last_freeze_analysis\"\n",
    "\n",
    "# Create the database engine with the following line \n",
    "engine = create_engine(db_string)\n",
    "\n",
    "# These two drop statements are to cleanup an old set of tablenames\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"DROP TABLE IF EXISTS stations;\")\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"DROP TABLE IF EXISTS observations;\")\n",
    "\n",
    "\n",
    "\n",
    "# RECREATE THE TABLES WITH DATA.  CREATE IN THIS ORDER TO DEAL WITH FK's\n",
    "\n",
    "# Save the observations DataFrame to a SQL table \"observations\"- Replace the table if it already exists\n",
    "observations_new_df.to_sql(name='observation', con=engine, if_exists='replace', index=False)   \n",
    "\n",
    "# Save the stations DataFrame to a SQL table \"stations\"- Replace the table if it already exists\n",
    "station_yearly_metrics_df.to_sql(name='station_yearly', con=engine, if_exists='replace', index=False)   \n",
    "\n",
    "# Save the stations DataFrame to a SQL table \"stations\"- Replace the table if it already exists\n",
    "station_metrics_full_df.to_sql(name='station', con=engine, if_exists='replace', index=False)   \n",
    "\n",
    "\n",
    "\n",
    "# Add primary keys\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE station ADD PRIMARY KEY (station_uid);\")\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE station_yearly ADD PRIMARY KEY (station_uid,year);\")\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE observation ADD PRIMARY KEY (station_uid,date);\")\n",
    "\n",
    "\n",
    "# Add foreign keys\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE station_yearly ADD CONSTRAINT stn_yrly_station_uid_fk FOREIGN KEY (station_uid) REFERENCES station (station_uid);\")\n",
    "\n",
    "\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"ALTER TABLE observation ADD CONSTRAINT obs_station_uid_fk FOREIGN KEY (station_uid) REFERENCES station (station_uid);\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79cce83be72e55c1187b298660b26fa831a7f54746f9fd5c4205698cac5dca1a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
